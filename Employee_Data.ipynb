{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Data Analysis using Spark\n",
    "\n",
    "Estimated time needed: **60** minutes\n",
    "\n",
    "This final project is similar to the Practice Project you did. In this project, you will not be provided with hints or solutions. You will create a DataFrame by loading data from a CSV file and apply transformations and actions using Spark SQL. This needs to be achieved by performing the following tasks:\n",
    "\n",
    "- Task 1: Generate DataFrame from CSV data.\n",
    "- Task 2: Define a schema for the data.\n",
    "- Task 3: Display schema of DataFrame.\n",
    "- Task 4: Create a temporary view.\n",
    "- Task 5: Execute an SQL query.\n",
    "- Task 6: Calculate Average Salary by Department.\n",
    "- Task 7: Filter and Display IT Department Employees.\n",
    "- Task 8: Add 10% Bonus to Salaries.\n",
    "- Task 9: Find Maximum Salary by Age.\n",
    "- Task 10: Self-Join on Employee Data.\n",
    "- Task 11: Calculate Average Employee Age.\n",
    "- Task 12: Calculate Total Salary by Department.\n",
    "- Task 13: Sort Data by Age and Salary.\n",
    "- Task 14: Count Employees in Each Department.\n",
    "- Task 15: Filter Employees with the letter o in the Name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/data/employees.csv\"\n",
    "local_filename = \"employees.csv\"\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "with open(local_filename, 'wb') as file:\n",
    "    file.write(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Generate a Spark DataFrame from the CSV data\n",
    "\n",
    "Read data from the provided CSV file, `employees.csv` and import it into a Spark DataFrame variable named `employees_df`.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"Employee Data Analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"employees.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Define a schema for the data\n",
    "\n",
    "Construct a schema for the input data and then utilize the defined schema to read the CSV file to create a DataFrame named `employees_df`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"Emp_No\", IntegerType(), True),\n",
    "    StructField(\"Emp_Name\", StringType(), True),\n",
    "    StructField(\"Salary\", FloatType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Department\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Emp_No=198, Emp_Name='Donald', Salary=2600, Age=29, Department='IT'),\n",
       " Row(Emp_No=199, Emp_Name='Douglas', Salary=2600, Age=34, Department='Sales'),\n",
       " Row(Emp_No=200, Emp_Name='Jennifer', Salary=4400, Age=36, Department='Marketing'),\n",
       " Row(Emp_No=201, Emp_Name='Michael', Salary=13000, Age=32, Department='IT'),\n",
       " Row(Emp_No=202, Emp_Name='Pat', Salary=6000, Age=39, Department='HR')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Display schema of DataFrame\n",
    "\n",
    "Display the schema of the `employees_df` DataFrame, showing all columns and their respective data types.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Emp_No: integer (nullable = true)\n",
      " |-- Emp_Name: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: Create a temporary view\n",
    "\n",
    "Create a temporary view named `employees` for the `employees_df` DataFrame, enabling Spark SQL queries on the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"employees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5: Execute an SQL query\n",
    "\n",
    "Compose and execute an SQL query to fetch the records from the `employees` view where the age of employees exceeds 30. Then, display the result of the SQL query, showcasing the filtered records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+---+----------+\n",
      "|Emp_No| Emp_Name|Salary|Age|Department|\n",
      "+------+---------+------+---+----------+\n",
      "|   198|   Donald|  2600| 29|        IT|\n",
      "|   199|  Douglas|  2600| 34|     Sales|\n",
      "|   200| Jennifer|  4400| 36| Marketing|\n",
      "|   201|  Michael| 13000| 32|        IT|\n",
      "|   202|      Pat|  6000| 39|        HR|\n",
      "|   203|    Susan|  6500| 36| Marketing|\n",
      "|   204|  Hermann| 10000| 29|   Finance|\n",
      "|   205|  Shelley| 12008| 33|   Finance|\n",
      "|   206|  William|  8300| 37|        IT|\n",
      "|   100|   Steven| 24000| 39|        IT|\n",
      "|   101|    Neena| 17000| 27|     Sales|\n",
      "|   102|      Lex| 17000| 37| Marketing|\n",
      "|   103|Alexander|  9000| 39| Marketing|\n",
      "|   104|    Bruce|  6000| 38|        IT|\n",
      "|   105|    David|  4800| 39|        IT|\n",
      "|   106|    Valli|  4800| 38|     Sales|\n",
      "|   107|    Diana|  4200| 35|     Sales|\n",
      "|   108|    Nancy| 12008| 28|     Sales|\n",
      "|   109|   Daniel|  9000| 35|        HR|\n",
      "|   110|     John|  8200| 31| Marketing|\n",
      "+------+---------+------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM employees\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6: Calculate Average Salary by Department\n",
    "\n",
    "Compose an SQL query to retrieve the average salary of employees grouped by department. Display the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|Department|       Avg_Salary|\n",
      "+----------+-----------------+\n",
      "|     Sales|5492.923076923077|\n",
      "|        HR|           5837.5|\n",
      "|   Finance|           5730.8|\n",
      "| Marketing|6633.333333333333|\n",
      "|        IT|           7400.0|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Department, AVG(Salary) as Avg_Salary FROM employees GROUP BY Department\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7: Filter and Display IT Department Employees\n",
    "\n",
    "Apply a filter on the `employees_df` DataFrame to select records where the department is `'IT'`. Display the filtered DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+---+----------+\n",
      "|Emp_No|Emp_Name|Salary|Age|Department|\n",
      "+------+--------+------+---+----------+\n",
      "|   198|  Donald|  2600| 29|        IT|\n",
      "|   201| Michael| 13000| 32|        IT|\n",
      "|   206| William|  8300| 37|        IT|\n",
      "|   100|  Steven| 24000| 39|        IT|\n",
      "|   104|   Bruce|  6000| 38|        IT|\n",
      "|   105|   David|  4800| 39|        IT|\n",
      "|   111|  Ismael|  7700| 32|        IT|\n",
      "|   129|   Laura|  3300| 38|        IT|\n",
      "|   132|      TJ|  2100| 34|        IT|\n",
      "|   136|   Hazel|  2200| 29|        IT|\n",
      "+------+--------+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM employees WHERE Department = 'IT'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8: Add 10% Bonus to Salaries\n",
    "\n",
    "Perform a transformation to add a new column named \"SalaryAfterBonus\" to the DataFrame. Calculate the new salary by adding a 10% bonus to each employee's salary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----------------+\n",
      "| Emp_Name|Salary|Salary_with_Bonus|\n",
      "+---------+------+-----------------+\n",
      "|   Donald|  2600|           2860.0|\n",
      "|  Douglas|  2600|           2860.0|\n",
      "| Jennifer|  4400|           4840.0|\n",
      "|  Michael| 13000|          14300.0|\n",
      "|      Pat|  6000|           6600.0|\n",
      "|    Susan|  6500|           7150.0|\n",
      "|  Hermann| 10000|          11000.0|\n",
      "|  Shelley| 12008|          13208.8|\n",
      "|  William|  8300|           9130.0|\n",
      "|   Steven| 24000|          26400.0|\n",
      "|    Neena| 17000|          18700.0|\n",
      "|      Lex| 17000|          18700.0|\n",
      "|Alexander|  9000|           9900.0|\n",
      "|    Bruce|  6000|           6600.0|\n",
      "|    David|  4800|           5280.0|\n",
      "|    Valli|  4800|           5280.0|\n",
      "|    Diana|  4200|           4620.0|\n",
      "|    Nancy| 12008|          13208.8|\n",
      "|   Daniel|  9000|           9900.0|\n",
      "|     John|  8200|           9020.0|\n",
      "+---------+------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Emp_Name, Salary, Salary * 1.1 as Salary_with_Bonus FROM employees\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 9: Find Maximum Salary by Age\n",
    "\n",
    "Group the data by age and calculate the maximum salary for each age group. Display the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "|Age|Max_Salary|\n",
      "+---+----------+\n",
      "| 31|      8200|\n",
      "| 34|      7800|\n",
      "| 28|     12008|\n",
      "| 27|     17000|\n",
      "| 26|      3600|\n",
      "| 37|     17000|\n",
      "| 35|      9000|\n",
      "| 39|     24000|\n",
      "| 38|      6000|\n",
      "| 29|     10000|\n",
      "| 32|     13000|\n",
      "| 33|     12008|\n",
      "| 30|      8000|\n",
      "| 36|      7900|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Age, MAX(Salary) as Max_Salary FROM employees GROUP BY Age\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 10: Self-Join on Employee Data\n",
    "\n",
    "Join the \"employees_df\" DataFrame with itself based on the \"Emp_No\" column. Display the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|Employee1|  Employee2|\n",
      "+---------+-----------+\n",
      "|   Donald|     Joshua|\n",
      "|   Donald|      Hazel|\n",
      "|   Donald|    Michael|\n",
      "|   Donald|  Alexander|\n",
      "|   Donald|    Hermann|\n",
      "|  Douglas|         TJ|\n",
      "|  Douglas|       Luis|\n",
      "|  Douglas|Jose Manuel|\n",
      "| Jennifer|       John|\n",
      "| Jennifer|      James|\n",
      "| Jennifer|      Payam|\n",
      "| Jennifer|        Guy|\n",
      "| Jennifer|      Susan|\n",
      "|  Michael|      Karen|\n",
      "|  Michael|     Ismael|\n",
      "|      Pat|       Adam|\n",
      "|      Pat|      David|\n",
      "|      Pat|  Alexander|\n",
      "|      Pat|     Steven|\n",
      "|    Susan|       John|\n",
      "+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT a.Emp_Name as Employee1, b.Emp_Name as Employee2 FROM employees a JOIN employees b ON a.Age = b.Age WHERE a.Emp_Name != b.Emp_Name\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 11: Calculate Average Employee Age\n",
    "\n",
    "Calculate the average age of employees using the built-in aggregation function. Display the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Avg_Age|\n",
      "+-------+\n",
      "|  33.56|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average age of employees\n",
    "from pyspark.sql.functions import avg \n",
    "spark.sql(\"SELECT AVG(Age) as Avg_Age FROM employees\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 12: Calculate Total Salary by Department\n",
    "\n",
    "Calculate the total salary for each department using the built-in aggregation function. Display the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|Department|Total_Salary|\n",
      "+----------+------------+\n",
      "|     Sales|       71408|\n",
      "|        HR|       46700|\n",
      "|   Finance|       57308|\n",
      "| Marketing|       59700|\n",
      "|        IT|       74000|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total salary for each department. Hint - User GroupBy and Aggregate functions\n",
    "from pyspark.sql.functions import sum \n",
    "spark.sql(\"SELECT Department, SUM(Salary) as Total_Salary FROM employees GROUP BY Department\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 13: Sort Data by Age and Salary\n",
    "\n",
    "Apply a transformation to sort the DataFrame by age in ascending order and then by salary in descending order. Display the sorted DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+---+----------+\n",
      "|Emp_No| Emp_Name|Salary|Age|Department|\n",
      "+------+---------+------+---+----------+\n",
      "|   137|   Renske|  3600| 26| Marketing|\n",
      "|   101|    Neena| 17000| 27|     Sales|\n",
      "|   114|      Den| 11000| 27|   Finance|\n",
      "|   108|    Nancy| 12008| 28|     Sales|\n",
      "|   130|    Mozhe|  2800| 28| Marketing|\n",
      "|   126|    Irene|  2700| 28|        HR|\n",
      "|   204|  Hermann| 10000| 29|   Finance|\n",
      "|   115|Alexander|  3100| 29|   Finance|\n",
      "|   134|  Michael|  2900| 29|     Sales|\n",
      "|   198|   Donald|  2600| 29|        IT|\n",
      "|   140|   Joshua|  2500| 29|   Finance|\n",
      "|   136|    Hazel|  2200| 29|        IT|\n",
      "|   120|  Matthew|  8000| 30|        HR|\n",
      "|   110|     John|  8200| 31| Marketing|\n",
      "|   127|    James|  2400| 31|        HR|\n",
      "|   201|  Michael| 13000| 32|        IT|\n",
      "|   111|   Ismael|  7700| 32|        IT|\n",
      "|   119|    Karen|  2500| 32|   Finance|\n",
      "|   205|  Shelley| 12008| 33|   Finance|\n",
      "|   124|    Kevin|  5800| 33| Marketing|\n",
      "+------+---------+------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM employees ORDER BY Age ASC, Salary DESC\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 14: Count Employees in Each Department\n",
    "\n",
    "Calculate the number of employees in each department. Display the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "|Department|Employee_Count|\n",
      "+----------+--------------+\n",
      "|     Sales|            13|\n",
      "|        HR|             8|\n",
      "|   Finance|            10|\n",
      "| Marketing|             9|\n",
      "|        IT|            10|\n",
      "+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "spark.sql(\"SELECT Department, COUNT(*) as Employee_Count FROM employees GROUP BY Department\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 15: Filter Employees with the letter o in the Name\n",
    "\n",
    "Apply a filter to select records where the employee's name contains the letter `'o'`. Display the filtered DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+---+----------+\n",
      "|Emp_No|   Emp_Name|Salary|Age|Department|\n",
      "+------+-----------+------+---+----------+\n",
      "|   198|     Donald|  2600| 29|        IT|\n",
      "|   199|    Douglas|  2600| 34|     Sales|\n",
      "|   110|       John|  8200| 31| Marketing|\n",
      "|   112|Jose Manuel|  7800| 34|        HR|\n",
      "|   130|      Mozhe|  2800| 28| Marketing|\n",
      "|   133|      Jason|  3300| 38|     Sales|\n",
      "|   139|       John|  2700| 36|     Sales|\n",
      "|   140|     Joshua|  2500| 29|   Finance|\n",
      "+------+-----------+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM employees WHERE Emp_Name LIKE '%o%'\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "prev_pub_hash": "aff0a6b4ec3a9cf15ae5d70a5c7ecac07e8a7f43b412a755232c9c99d1062fc8"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
